{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69809eb0-e5fe-4b07-99c6-f83dd43fbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json, re, time\n",
    "from urllib.parse import urljoin\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "BASE = os.getenv(\"OPENWEBUI_BASE\", \"https://ai.create.kcl.ac.uk\")  # no trailing slash\n",
    "TOKEN = os.getenv(\"OPENWEBUI_TOKEN\", \"sk-67123084b3384c1a8f70461dd9c60c5b\")                 # don't hardcode in code\n",
    "TIMEOUT = 120\n",
    "TRANSCRIPT_PATH = f\"psychs_transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a199a6b-f3c6-4afe-b6f1-fe6ea281d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_session = requests.Session()\n",
    "\n",
    "def _headers():\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",   \n",
    "    }\n",
    "\n",
    "def _url(path: str) -> str:\n",
    "    # ensure exactly one slash between base and path\n",
    "    return urljoin(BASE.rstrip(\"/\") + \"/\", path.lstrip(\"/\"))\n",
    "\n",
    "def collect_ids(obj):\n",
    "    found = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            if k == \"id\":\n",
    "                found.append(v)\n",
    "            found.extend(collect_ids(v))\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            found.extend(collect_ids(item))\n",
    "    return found\n",
    "\n",
    "def list_models():\n",
    "    \"\"\"\n",
    "    Returns the raw JSON from /api/models.\n",
    "    Most Open WebUI builds return {\"data\": [ ...models... ]}.\n",
    "    \"\"\"\n",
    "    r = _session.get(_url(\"/api/models\"), headers=_headers(), timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def _post_json(path: str, payload: dict):\n",
    "    # IMPORTANT: use a longer read timeout to avoid partial responses\n",
    "    r = _session.post(\n",
    "        _url(path),\n",
    "        headers=_headers(),\n",
    "        json=payload,\n",
    "        timeout=(10, 300),\n",
    "    )\n",
    "\n",
    "    def _parse_response_text(txt: str, ctype: str):\n",
    "        if not txt or not txt.strip():\n",
    "            raise RuntimeError(\"Empty response body (server returned no JSON).\")\n",
    "\n",
    "        s = txt.lstrip()\n",
    "        # JSON-as-text with wrong content-type\n",
    "        if s.startswith(\"{\") or s.startswith(\"[\"):\n",
    "            return json.loads(s)\n",
    "\n",
    "        # SSE or noisy logs\n",
    "        if \"text/event-stream\" in ctype or \"data:\" in txt:\n",
    "            chunks = []\n",
    "            for line in txt.splitlines():\n",
    "                line = line.strip()\n",
    "                if not line.startswith(\"data:\"):\n",
    "                    continue\n",
    "                if line == \"data: [DONE]\":\n",
    "                    break\n",
    "                try:\n",
    "                    obj = json.loads(line[5:].strip())\n",
    "                except Exception:\n",
    "                    continue\n",
    "                ch = (obj.get(\"choices\") or [{}])[0]\n",
    "                delta = ch.get(\"delta\") or {}\n",
    "                piece = delta.get(\"content\")\n",
    "                if piece is None:\n",
    "                    msg = ch.get(\"message\") or {}\n",
    "                    piece = msg.get(\"content\")\n",
    "                if piece:\n",
    "                    chunks.append(piece)\n",
    "            if chunks:\n",
    "                return {\"choices\": [{\"message\": {\"content\": \"\".join(chunks)}}]}\n",
    "\n",
    "        # HTML error page or mixed logs: try to pull first JSON object\n",
    "        m = re.search(r\"\\{.*\\}\", txt, flags=re.S)\n",
    "        if m:\n",
    "            try:\n",
    "                return json.loads(m.group(0))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Give a helpful error\n",
    "        snippet = txt[:500].replace(\"\\n\", \"\\\\n\")\n",
    "        raise RuntimeError(\n",
    "            f\"Unexpected non-JSON response (content-type={ctype}). \"\n",
    "            f\"First 500 chars: {snippet}\"\n",
    "        )\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        # return server body snippet to help debug\n",
    "        raise RuntimeError(f\"{r.status_code} {_url(path)}\\nResponse: {r.text[:500]}\")\n",
    "\n",
    "    ctype = (r.headers.get(\"content-type\") or \"\").lower()\n",
    "\n",
    "    # Try normal JSON first\n",
    "    try:\n",
    "        if \"application/json\" in ctype:\n",
    "            return r.json()\n",
    "        return _parse_response_text(r.text, ctype)\n",
    "    except Exception as e:\n",
    "        # One quick retry (server sometimes flushes late / returns partial)\n",
    "        time.sleep(0.5)\n",
    "        r2 = _session.post(\n",
    "            _url(path),\n",
    "            headers=_headers(),\n",
    "            json=payload,\n",
    "            timeout=(10, 300),\n",
    "        )\n",
    "        if r2.status_code >= 400:\n",
    "            raise RuntimeError(f\"{r2.status_code} {_url(path)}\\nResponse: {r2.text[:500]}\")\n",
    "        ctype2 = (r2.headers.get(\"content-type\") or \"\").lower()\n",
    "        if \"application/json\" in ctype2:\n",
    "            return r2.json()\n",
    "        return _parse_response_text(r2.text, ctype2)\n",
    "    \n",
    "def _pick_model(explicit: str | None = None) -> str:\n",
    "    if explicit:\n",
    "        return explicit\n",
    "    raw = list_models()\n",
    "    models = raw.get(\"data\") if isinstance(raw, dict) else raw\n",
    "    if not models:\n",
    "        raise RuntimeError(\"No models available on this Open WebUI server.\")\n",
    "    first = models[0]\n",
    "    # handle either dict or plain string\n",
    "    if isinstance(first, dict):\n",
    "        return first.get(\"id\") or first.get(\"name\") or next(iter(first.values()))\n",
    "    return str(first)\n",
    "\n",
    "def _extract_assistant_text(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Works with OpenAI-compatible responses.\n",
    "    \"\"\"\n",
    "    # Typical: {\"choices\":[{\"message\":{\"role\":\"assistant\",\"content\":\"...\"}}]}\n",
    "    try:\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        # Some servers use \"content\" directly on the choice\n",
    "        try:\n",
    "            return data[\"choices\"][0][\"content\"]\n",
    "        except Exception:\n",
    "            raise RuntimeError(f\"Unexpected response schema:\\n{data}\")\n",
    "\n",
    "def chat(msg: str, model: str | None = None) -> str:\n",
    "    model = _pick_model(model)\n",
    "    payload = {\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": msg}],\"stream\": False}\n",
    "\n",
    "    # Try documented path first, then OpenAI-compatible fallback\n",
    "    errors = []\n",
    "    for path in (\"/api/chat/completions\", \"/v1/chat/completions\"):\n",
    "        try:\n",
    "            data = _post_json(path, payload)\n",
    "            return _extract_assistant_text(data)\n",
    "        except RuntimeError as e:\n",
    "            errors.append(f\"{path} -> {e}\")\n",
    "\n",
    "    raise RuntimeError(\"Both endpoints failed:\\n\\n\" + \"\\n\\n\".join(errors))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(chat(\"Say hi in one sentence.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6e2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transcript_files = [f for f in Path(TRANSCRIPT_PATH).glob(\"*.txt\") \n",
    "                   if \"prompt\" not in f.name and \"assessment\" not in f.name]\n",
    "target_ids = {\"BM97794\", \"ME39294\", \"NC30190\"}\n",
    "\n",
    "matches = [f for f in transcript_files if any(tid in f.name for tid in target_ids)]\n",
    "outputs_dir = Path(\"outputs_score\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffa74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Saved: outputs_score/psychs_transcripts/PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Dom_v2_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED.txt\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED_assessment_Dom_v2_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0043_session002_REDACTED.txt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Both endpoints failed:\n\n/api/chat/completions -> 502 https://ai.create.kcl.ac.uk/api/chat/completions\nResponse: <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html><head>\n<title>502 Proxy Error</title>\n</head><body>\n<h1>Proxy Error</h1>\n<p>The proxy server received an invalid\r\nresponse from an upstream server.<br />\r\nThe proxy server could not handle the request<p>Reason: <strong>Error reading from remote server</strong></p></p>\n</body></html>\n\n\n/v1/chat/completions -> Unexpected non-JSON response (content-type=text/html; charset=utf-8). First 500 chars: \r\\n\r\\n<!-- Copyright (C) Microsoft Corporation. All rights reserved. -->\r\\n<!DOCTYPE html>\r\\n<html dir=\"ltr\" class=\"\" lang=\"en\">\r\\n<head>\r\\n    <title>Sign in to your account</title>\r\\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\r\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=2.0, user-scalable=yes\">\r\\n    <meta http-equiv=\"Pragma\" content=\"no-cache\">\r\\n    <meta http-equiv=\"Exp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m prompt = prompt_template.format(transcript=transcript)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscript_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m assessment = \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or generate_assessment(prompt, model=\"qwen3\")\u001b[39;00m\n\u001b[32m     18\u001b[39m output_file = \u001b[38;5;28mstr\u001b[39m(transcript_file).replace(\u001b[33m\"\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_assessment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m out_path = outputs_dir / output_file\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 160\u001b[39m, in \u001b[36mchat\u001b[39m\u001b[34m(msg, model)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m         errors.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mBoth endpoints failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(errors))\n",
      "\u001b[31mRuntimeError\u001b[39m: Both endpoints failed:\n\n/api/chat/completions -> 502 https://ai.create.kcl.ac.uk/api/chat/completions\nResponse: <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html><head>\n<title>502 Proxy Error</title>\n</head><body>\n<h1>Proxy Error</h1>\n<p>The proxy server received an invalid\r\nresponse from an upstream server.<br />\r\nThe proxy server could not handle the request<p>Reason: <strong>Error reading from remote server</strong></p></p>\n</body></html>\n\n\n/v1/chat/completions -> Unexpected non-JSON response (content-type=text/html; charset=utf-8). First 500 chars: \r\\n\r\\n<!-- Copyright (C) Microsoft Corporation. All rights reserved. -->\r\\n<!DOCTYPE html>\r\\n<html dir=\"ltr\" class=\"\" lang=\"en\">\r\\n<head>\r\\n    <title>Sign in to your account</title>\r\\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\r\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=2.0, user-scalable=yes\">\r\\n    <meta http-equiv=\"Pragma\" content=\"no-cache\">\r\\n    <meta http-equiv=\"Exp"
     ]
    }
   ],
   "source": [
    "\n",
    "# All at once\n",
    "prompt_name = 'Dom_v2'\n",
    "\n",
    "with open(f'prompt_{prompt_name}.txt', 'r') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "\n",
    "# model = 'gemma3n:latest'\n",
    "\n",
    "for model in ['gemma3n:latest']:\n",
    "\n",
    "    for transcript_file in matches:\n",
    "        with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            transcript = f.read()\n",
    "\n",
    "        prompt = prompt_template.format(transcript=transcript)\n",
    "\n",
    "        print(f\"\\nProcessing: {transcript_file.name}\")\n",
    "        assessment = chat(prompt,model)  # or generate_assessment(prompt, model=\"qwen3\")\n",
    "\n",
    "        output_file = str(transcript_file).replace(\".txt\", f\"_assessment_{prompt_name}_{model}.txt\")\n",
    "        out_path = outputs_dir / output_file\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"File: {transcript_file.name}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(assessment)\n",
    "\n",
    "        print(f\"Saved: {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22639a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "_num = r'[-+]?(?:\\d+(?:\\.\\d+)?|\\.\\d+)(?:[eE][-+]?\\d+)?'  # int, float, .float, sci\n",
    "\n",
    "def _to_float(s: str) -> float:\n",
    "    s = s.replace(\",\", \"\")  # allow \"1,234.5\"\n",
    "    # s matches _num by construction, so float() is safe without try/except\n",
    "    return float(s)\n",
    "\n",
    "# use int?\n",
    "def extract_number(text: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Returns the first 'meaningful' number it finds:\n",
    "      1) percentage like '87%'  -> 87.0\n",
    "      2) fraction  like '4/6'   -> 4.0  (numerator)\n",
    "      3) plain number           -> value\n",
    "    If none found, returns None.\n",
    "    \"\"\"\n",
    "    # 1) percentage\n",
    "    m = re.search(rf'(?<!\\d)({_num})\\s*%', text)\n",
    "    if m:\n",
    "        return _to_float(m.group(1))\n",
    "\n",
    "    # 2) fraction (return the numerator as the number)\n",
    "    m = re.search(rf'({_num})\\s*/\\s*({_num})', text)\n",
    "    if m:\n",
    "        return _to_float(m.group(1))\n",
    "\n",
    "    # 3) plain number\n",
    "    m = re.search(rf'({_num})', text)\n",
    "    return _to_float(m.group(1)) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7c3f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Estimated severity score: 3.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED.txt\n",
      "Estimated severity score: 2.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0043_session002_REDACTED.txt\n",
      "Estimated severity score: 3.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0043_session002_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0038_session001_REDACTED.txt\n",
      "Estimated severity score: 2.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0038_session001_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientBM_BM97794_interviewAudioTranscript_psychs_day0069_session002_REDACTED.txt\n",
      "Estimated severity score: 3.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientBM_BM97794_interviewAudioTranscript_psychs_day0069_session002_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n",
      "\n",
      "Processing: PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Estimated severity score: 3.0\n",
      "Saved: outputs_score/psychs_transcripts/PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Alejo_sev_gemma3n:latest.txt\n"
     ]
    }
   ],
   "source": [
    "# Step by step\n",
    "\n",
    "# Severity\n",
    "#  \n",
    "model ='gemma3n:latest'\n",
    "prompt_name = 'Alejo'\n",
    "with open(f'prompt_{prompt_name}_sev.txt', 'r') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "sev_scores = []\n",
    "for transcript_file in matches:\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        transcript = f.read()\n",
    "\n",
    "    prompt = prompt_template.format(transcript=transcript)\n",
    "\n",
    "    print(f\"\\nProcessing: {transcript_file.name}\")\n",
    "    assessment = chat(prompt,model)  # or generate_assessment(prompt, model=\"qwen3\")\n",
    "    sev_score = extract_number(assessment)\n",
    "    sev_scores.append(sev_score)\n",
    "    print(f'Estimated severity score: {sev_score}')\n",
    "\n",
    "    output_file = str(transcript_file).replace(\".txt\", f\"_assessment_{prompt_name}_sev_{model}.txt\")\n",
    "    out_path = outputs_dir / output_file\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"File: {transcript_file.name}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(assessment)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ac329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Estimated frequency score: 2.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientBM_BM97794_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED.txt\n",
      "Estimated frequency score: 1.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0094_session004_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0043_session002_REDACTED.txt\n",
      "Estimated frequency score: 3.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0043_session002_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientME_ME39294_interviewAudioTranscript_psychs_day0038_session001_REDACTED.txt\n",
      "Estimated frequency score: 40.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientME_ME39294_interviewAudioTranscript_psychs_day0038_session001_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n",
      "\n",
      "Processing: PrescientBM_BM97794_interviewAudioTranscript_psychs_day0069_session002_REDACTED.txt\n",
      "Estimated frequency score: 2.0\n",
      "Saved: outputs_score/psychs_transcripts/PrescientBM_BM97794_interviewAudioTranscript_psychs_day0069_session002_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n",
      "\n",
      "Processing: PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Estimated frequency score: 2.0\n",
      "Saved: outputs_score/psychs_transcripts/PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Alejo_freq_gemma3n:latest.txt\n"
     ]
    }
   ],
   "source": [
    "# Step by step\n",
    "\n",
    "# Frequency\n",
    "\n",
    "with open(f'prompt_{prompt_name}_freq.txt', 'r') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "freq_scores = []\n",
    "for transcript_file,sev_score in zip(matches,sev_scores):\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        transcript = f.read()\n",
    "\n",
    "    prompt = prompt_template.format(transcript=transcript,sev_score=sev_score)\n",
    "\n",
    "    print(f\"\\nProcessing: {transcript_file.name}\")\n",
    "    assessment = chat(prompt,model)  # or generate_assessment(prompt, model=\"qwen3\")\n",
    "\n",
    "    output_file = str(transcript_file).replace(\".txt\", f\"_assessment_{prompt_name}_freq_{model}.txt\")\n",
    "    out_path = outputs_dir / output_file\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    freq_score = extract_number(assessment)\n",
    "    freq_scores.append(freq_score)\n",
    "    print(f'Estimated frequency score: {freq_score}')\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"File: {transcript_file.name}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(assessment)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c9745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED.txt\n",
      "Saved: outputs_score/psychs_transcripts/PronetNC_NC30190_interviewAudioTranscript_psychs_day0001_session001_REDACTED_assessment_Alejo_sum_gemma3n:latest.txt\n"
     ]
    }
   ],
   "source": [
    "# Step by step\n",
    "\n",
    "# Summary\n",
    "\n",
    "with open(f'prompt_{prompt_name}_sum.txt', 'r') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "\n",
    "for transcript_file,sev_score,freq_score in zip(matches,sev_scores,freq_scores):\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        transcript = f.read()\n",
    "\n",
    "    prompt = prompt_template.format(transcript=transcript,sev_score=sev_score,freq_score=freq_score)\n",
    "\n",
    "    print(f\"\\nProcessing: {transcript_file.name}\")\n",
    "    assessment = chat(prompt,model)  # or generate_assessment(prompt, model=\"qwen3\")\n",
    "\n",
    "    output_file = str(transcript_file).replace(\".txt\", f\"_assessment_{prompt_name}_sum_{model}.txt\")\n",
    "    out_path = outputs_dir / output_file\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"File: {transcript_file.name}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(assessment)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cbd2d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qwen3',\n",
       " 'qwen3',\n",
       " 'qwen3',\n",
       " 'gpt-oss:20b',\n",
       " 'gpt-oss:20b',\n",
       " 'gpt-oss:20b',\n",
       " 'gemma3n:latest',\n",
       " 'gemma3n:latest',\n",
       " 'gemma3n:latest',\n",
       " 'gemma3:1b',\n",
       " 'gemma3:1b',\n",
       " 'gemma3:1b']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BM97794 (Severity = 3; Frequency = 3)\n",
    "# ME39294 day 38 (Severity = 4; Frequency = 6)\n",
    "# NC30190 (Severity = 6; Frequency = 5)\n",
    "collect_ids(list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbf97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
